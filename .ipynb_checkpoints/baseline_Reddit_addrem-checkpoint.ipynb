{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from attack import *\n",
    "from adv_immunity import *\n",
    "from baseline import *\n",
    "import csv\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "np_load_old = np.load\n",
    "np.aload = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "%load_ext memory_profiler\n",
    "seed = 15\n",
    "alpha = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 309.86 MiB, increment: -0.48 MiB\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "file_name = 'data/nei_reddit.npz'\n",
    "graph = load_dataset(file_name=file_name)\n",
    "ori_adj, ori_attr, labels = standardize(adj_matrix=graph['adj_matrix'],\n",
    "                             attr_matrix=graph['attr_matrix'],\n",
    "                             labels=graph['labels'])\n",
    "adj = torch.from_numpy(ori_adj.todense()).float()\n",
    "edge_num = adj.sum().item()\n",
    "# loaded = np.load('data/reddit_pretrained_logits.npz')\n",
    "# logits = loaded['logits']\n",
    "logits = np.load('data/my_reddit_logits.npy')\n",
    "labels = np.load('output_csv/reddit_predict.npy')\n",
    "%memit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "x = [0, 2, 4, 6]\n",
    "# strength = [11, 9 ,7, 5]  local_budget=deg-11+strength\n",
    "deg = ori_adj.sum(1).A1.astype(np.int32)\n",
    "local_budget = np.maximum(deg-x[i] , 0)\n",
    "# 生成可扰动边\n",
    "fragile = get_fragile(adj=ori_adj, threat_model='add_rem')\n",
    "n, nc = logits.shape\n",
    "con_budget_local = np.maximum(deg-0 , 0)\n",
    "mode = 'add_rem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori_ppr_changing = np.aload('my_reddit/add_one_local_6/ori_ppr_changing.npy').item()\n",
    "file = 'my_reddit/add_rem_baseline.csv'\n",
    "budget_arr = [51614, 103244]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 边的重要性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local：bridgeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51614\n",
      "After control 51614: Ratio of certified all nodes: 0.286738\n",
      "-1.261024\n",
      "103244\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'new_i' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bb4fe6f799e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcon_budget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbudget_arr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon_budget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0madj_controlled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimmune_edge_control_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_controlled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_edge_neighb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon_budget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcon_ppr_changing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpagerank_adj_changing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mori_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfragile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_controlled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_budget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcon_worst_margins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworst_margins_given_k_squared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon_ppr_changing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/adv_immunity/baseline.py\u001b[0m in \u001b[0;36mimmune_edge_control_baseline\u001b[0;34m(adj_controlled, sort_edge, cur_i, con_budget)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0madj_controlled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'new_i' referenced before assignment"
     ]
    }
   ],
   "source": [
    "\n",
    "big_edge_neighb = edge_neighb_bridgeness(ori_adj, True)\n",
    "\n",
    "# 各类别控制相同数量的边\n",
    "cur_i = 0\n",
    "cur_controlled = torch.ones(n,n)\n",
    "for con_budget in budget_arr:\n",
    "    print(con_budget)\n",
    "    adj_controlled, cur_i = immune_edge_control_baseline(cur_controlled, big_edge_neighb, cur_i, con_budget)\n",
    "    con_ppr_changing = pagerank_adj_changing(ori_adj, alpha, fragile, adj_controlled, local_budget, logits)\n",
    "    con_worst_margins = worst_margins_given_k_squared(con_ppr_changing, labels, logits)\n",
    "    print('After control {:d}: Ratio of certified all nodes: {:.6f}'.format(con_budget, (con_worst_margins>0).mean()))\n",
    "    print('worst-case margin%.6f' % con_worst_margins.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global：edge_betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 从大到小\n",
    "\n",
    "big_edge_between = edge_importance(ori_adj, True)\n",
    "\n",
    "# 各类别控制相同数量的边\n",
    "cur_i = 0\n",
    "cur_controlled = torch.ones(n,n)\n",
    "for con_budget in budget_arr:\n",
    "    print(con_budget)\n",
    "    adj_controlled, cur_i = immune_edge_control_baseline(cur_controlled, big_edge_neighb, cur_i, con_budget)\n",
    "    con_ppr_changing = pagerank_adj_changing(ori_adj, alpha, fragile, adj_controlled, local_budget, logits)\n",
    "    con_worst_margins = worst_margins_given_k_squared(con_ppr_changing, labels, logits)\n",
    "    print('After control {:d}: Ratio of certified all nodes: {:.6f}'.format(con_budget, (con_worst_margins>0).mean()))\n",
    "    print('%.6f' % con_worst_margins.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51614\n",
      "add_rem\n",
      "After control 51614: Ratio of certified all nodes: 0.282177\n",
      "-1.3161702317697943\n",
      "103244\n",
      "add_rem\n",
      "After control 103244: Ratio of certified all nodes: 0.282177\n",
      "-1.3109983207734406\n"
     ]
    }
   ],
   "source": [
    "\n",
    "similarity = 'Jaccard'\n",
    "simil_matrix, disconnect_simil = similarity_matrix(ori_adj, ori_attr, labels, similarity,mode)\n",
    "cur_controlled = torch.ones((n,n))\n",
    "for con_budget in budget_arr:\n",
    "    print(con_budget)\n",
    "    adj_controlled, simil_matrix, disconnect_simil =  ICEU(ori_adj, cur_controlled, simil_matrix, disconnect_simil, con_budget,mode)\n",
    "    con_ppr_changing = pagerank_adj_changing(ori_adj, alpha, fragile, adj_controlled, local_budget, logits)\n",
    "    con_worst_margins = worst_margins_given_k_squared(con_ppr_changing, labels, logits)\n",
    "    print('After control {:d}: Ratio of certified all nodes: {:.6f}'.format(con_budget, (con_worst_margins>0).mean()))\n",
    "    print(con_worst_margins.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51614\n",
      "add_rem\n",
      "After control 51614: Ratio of certified all nodes: 0.281199\n",
      "worst margin -1.371398692763902\n",
      "103244\n",
      "add_rem\n",
      "After control 103244: Ratio of certified all nodes: 0.282177\n",
      "worst margin -1.3497734440892841\n"
     ]
    }
   ],
   "source": [
    "\n",
    "similarity = 'cosine'\n",
    "simil_matrix, disconnect_simil = similarity_matrix(ori_adj, ori_attr, labels, similarity,mode)\n",
    "cur_controlled = torch.ones((n,n))\n",
    "for con_budget in budget_arr:\n",
    "    print(con_budget)\n",
    "    adj_controlled, simil_matrix, disconnect_simil =  ICEU(ori_adj, cur_controlled, simil_matrix, disconnect_simil, con_budget,mode)\n",
    "    con_ppr_changing = pagerank_adj_changing(ori_adj, alpha, fragile, adj_controlled, local_budget, logits)\n",
    "    con_worst_margins = worst_margins_given_k_squared(con_ppr_changing, labels, logits)\n",
    "    print('After control {:d}: Ratio of certified all nodes: {:.6f}'.format(con_budget, (con_worst_margins>0).mean()))\n",
    "    print('worst margin',con_worst_margins.mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51614\n",
      "Ratio of robust node: 0.272825\n",
      "Variance:0.000000\n",
      "Worst margin: -1.511830\n",
      "Variance:0.000003\n",
      "103244\n",
      "Ratio of robust node: 0.272890\n",
      "Variance:0.000000\n",
      "Worst margin: -1.505662\n",
      "Variance:0.000051\n"
     ]
    }
   ],
   "source": [
    "# 基于普通的随机控制\n",
    "\n",
    "normal_fragile = list(np.column_stack(np.ones((n,n)).nonzero()))\n",
    "for con_budget in budget_arr:\n",
    "    print(con_budget)\n",
    "    rand_num = 10\n",
    "    rob_ratio_all = []\n",
    "    con_norm_all = []\n",
    "    for i in range(rand_num):\n",
    "        cur_controlled = np.ones((n,n))\n",
    "        adj_controlled = random_control(normal_fragile, cur_controlled,con_budget,n,mode)\n",
    "        con_ppr_changing = pagerank_adj_changing(ori_adj, alpha, fragile, torch.from_numpy(adj_controlled), local_budget, logits)\n",
    "        con_worst_margins = worst_margins_given_k_squared(con_ppr_changing, labels, logits)\n",
    "        rob_ratio_all.append((con_worst_margins>0).mean())\n",
    "        con_norm_all.append(con_worst_margins.mean())\n",
    "        del adj_controlled\n",
    "\n",
    "    con_norm_all = np.array(con_norm_all)\n",
    "    rob_ratio_all = np.array(rob_ratio_all)\n",
    "    print('Ratio of robust node: %.6f' % rob_ratio_all.mean())\n",
    "    print('Variance:%.6f' % rob_ratio_all.var())\n",
    "    print('Worst margin: %.6f' % con_norm_all.mean())\n",
    "    print('Variance:%.6f' % con_norm_all.var())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_ppr_changing = np.aload('my_reddit/add_rem_one_local_6_ori_ppr_changing.npy').item()\n",
    "for c1 in range(nc):\n",
    "    for c2 in range(nc):\n",
    "        if c1 != c2:\n",
    "            changing = ori_ppr_changing[c1,c2]['changing']\n",
    "            tmp = torch.nonzero(changing!=0)\n",
    "            if c1 == 0 and c2 == 1:\n",
    "                attack_fragile = tmp\n",
    "            else:\n",
    "                attack_fragile = torch.cat((attack_fragile, tmp),0)\n",
    "                attack_fragile = torch.unique(attack_fragile, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attackfrag(nc,con_ppr_changing):\n",
    "    for c1 in range(nc):\n",
    "        for c2 in range(nc):\n",
    "            if c1 != c2:\n",
    "                changing = con_ppr_changing[c1,c2]['changing']\n",
    "                tmp = torch.nonzero(changing!=0)\n",
    "                if c1 == 0 and c2 == 1:\n",
    "                    attack_fragile = tmp\n",
    "                else:\n",
    "                    attack_fragile = torch.cat((attack_fragile, tmp),0)\n",
    "                    attack_fragile = torch.unique(attack_fragile, dim=0)\n",
    "                \n",
    "    return attack_fragile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51614\n",
      "Ratio of robust node: 0.336298\n",
      "Variance:0.000034\n",
      "Worst margin: -0.765917\n",
      "Variance:0.001793\n",
      "103244\n"
     ]
    }
   ],
   "source": [
    "# 基于攻击的随机控制\n",
    "for con_budget in budget_arr:\n",
    "    print(con_budget)\n",
    "    rand_num = 10\n",
    "    rob_ratio_all = []\n",
    "    con_norm_all = []\n",
    "    for i in range(rand_num):\n",
    "        cur_controlled = np.ones((n,n))\n",
    "        cur_cnum = 0\n",
    "        while cur_cnum < con_budget:\n",
    "            if len(attack_fragile) < (con_budget-cur_cnum):\n",
    "                each_con_num = int(0.5*len(attack_fragile))\n",
    "            else:\n",
    "                each_con_num =(con_budget-cur_cnum)\n",
    "            adj_controlled = random_control(list(attack_fragile), cur_controlled, each_con_num, n, mode)\n",
    "            con_ppr_changing = pagerank_adj_changing(ori_adj, alpha, fragile, torch.from_numpy(adj_controlled), local_budget, logits)\n",
    "            attack_fragile = compute_attackfrag(nc, con_ppr_changing)\n",
    "            cur_controlled = adj_controlled.copy()\n",
    "            cur_cnum = np.where(cur_controlled==0)[0].shape[0]\n",
    "            \n",
    "        con_ppr_changing = pagerank_adj_changing(ori_adj, alpha, fragile, torch.from_numpy(adj_controlled), local_budget, logits)\n",
    "        con_worst_margins = worst_margins_given_k_squared(con_ppr_changing, labels, logits)\n",
    "        rob_ratio_all.append((con_worst_margins>0).mean())\n",
    "        con_norm_all.append(con_worst_margins.mean())\n",
    "        del adj_controlled\n",
    "\n",
    "    con_norm_all = np.array(con_norm_all)\n",
    "    rob_ratio_all = np.array(rob_ratio_all)\n",
    "    print('Ratio of robust node: %.6f' % rob_ratio_all.mean())\n",
    "    print('Variance:%.6f' % rob_ratio_all.var())\n",
    "    print('Worst margin: %.6f' % con_norm_all.mean())\n",
    "    print('Variance:%.6f' % con_norm_all.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_arr = np.arange(0.02,0.22,0.02)\n",
    "with open(file, 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['AttackRandom'])\n",
    "dataframe = pd.DataFrame({u'控制边数':budget_arr,u'鲁棒节点比例':robust_arr,\n",
    "                          u'边距':con_worst_margins_arr})\n",
    "dataframe.to_csv(file, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
